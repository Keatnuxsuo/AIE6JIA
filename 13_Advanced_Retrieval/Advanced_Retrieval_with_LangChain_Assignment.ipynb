{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- 🤝 Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- 🤝 Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/233.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.1/378.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Comparing Retrievals\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-16 14:52:34--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: ‘john_wick_1.csv’\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-16 14:52:34 (78.0 MB/s) - ‘john_wick_1.csv’ saved [19628/19628]\n",
            "\n",
            "--2025-05-16 14:52:34--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: ‘john_wick_2.csv’\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2025-05-16 14:52:35 (3.07 MB/s) - ‘john_wick_2.csv’ saved [14747/14747]\n",
            "\n",
            "--2025-05-16 14:52:35--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: ‘john_wick_3.csv’\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-16 14:52:36 (64.6 MB/s) - ‘john_wick_3.csv’ saved [13888/13888]\n",
            "\n",
            "--2025-05-16 14:52:36--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: ‘john_wick_4.csv’\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-16 14:52:36 (79.2 MB/s) - ‘john_wick_4.csv’ saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 5, 13, 14, 52, 38, 299252)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, people generally liked John Wick. Many reviews are highly positive, praising its action sequences, style, and Keanu Reeves' performance, with ratings like 9 and 10 out of 10. Several reviewers mention that it is a must-see for action fans and highlight its entertainment value. While there are some mixed reviews with lower ratings (such as a 5 or 6), the overall tone suggests that the film was well-received and appreciated by most viewers.\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. The URLs to those reviews are:\\n\\n1. [Review URL: /review/rw4854296/?ref_=tt_urv](https://example.com/review/rw4854296/?ref_=tt_urv)\\n\\nPlease note that the URLs provided are as per the data; you may need to append the base URL of the review site to access them directly.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick film series, the story centers around John Wick, a retired and highly skilled assassin, who is pulled back into the violent underworld of crime after personal tragedy strikes. The first film depicts Wick seeking vengeance for the killing of his dog and the theft of his car by criminals, which leads him to unleash a brutal and meticulously orchestrated rampage against those who cross him. As the series progresses, he becomes embroiled in complex criminal alliances and conflicts, with themes of revenge, consequence, and the code of the assassin world playing significant roles. The films are known for their stylish action sequences, deep world-building, and Keanu Reeves’ compelling portrayal of Wick.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people\\'s opinions on John Wick are mixed. Some reviews highly praise the first film for its stylish action and straightforward plot, suggesting that many viewers liked it. However, other reviews, like the one for John Wick 4, are more critical, describing the latest installment as \"almost three hours of nothing\" and the weakest in the series. Additionally, the review for John Wick 3 describes it as \"boring, dull, and full of stereotypes,\" indicating some viewers did not enjoy it.\\n\\nOverall, while many fans appreciate the style, action, and Keanu Reeves\\' performance, others feel the series has declined or do not enjoy certain installments. Therefore, people\\'s general opinion about John Wick varies, with a significant number of fans liking it, but there are also a notable proportion who are not favorable toward it.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, there are no reviews with a rating of 10.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick film series, the story revolves around John Wick, a former hitman who is drawn back into the violent assassin world after a series of events. The first movie, \"John Wick,\" features Keanu Reeves as John Wick, who seeks vengeance after criminals steal his car and kill his dog, a gift from his deceased wife. The series showcases intense, highly choreographed action scenes and a complex underworld with its own rules and societies. As the series progresses, Wick navigates deep into the assassin universe, facing various enemies and challenges, all while dealing with themes of revenge, honor, and survival.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, people generally liked John Wick. The reviews are highly positive, with ratings of 9 and 10 out of 10, and enthusiastic descriptions praising its action sequences, style, and Keanu Reeves' performance. However, there is at least one less favorable review with a rating of 5, indicating some viewers' opinions may vary. Overall, the majority of the feedback in the provided context suggests that people generally liked John Wick.\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. Here are the URLs to those reviews:\\n\\n1. Review Title: \"A Masterpiece & Brilliant Sequel\"\\n   URL: /review/rw4854296/?ref_=tt_urv\\n\\n2. Review Title: \"Most American action flicks released these days have poor screenplays and overuse computer-generated imagery. The John Wick franchise is one of the few exceptions, along with Mission Impossible. These franchises keep getting better with every entry.\"\\n   URL: /review/rw4860412/?ref_=tt_urv'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick movies, John Wick is a retired hitman who initially comes out of retirement to avenge the killing of his dog and the theft of his car, which were tied to the loss of his wife. He is a highly skilled and lethal assassin who is targeted by various criminal organizations after he reenters the world of violence. Throughout the series, Wick faces challenges from mobsters and hitmen as he seeks to settle old scores and deal with threats to his life. His actions often violate mafia rules, which leads to him being pursued by professional killers, and he must navigate a dangerous world of crime, revenge, and loyalty.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. Many reviews are highly positive, praising its action sequences, style, and Keanu Reeves\\' performance. Some reviews gave high ratings like 9 or 10 out of 10, and phrases like \"I cannot recommend this movie enough,\" \"slick, violent fun,\" and \"a must-see for action fans\" indicate a strong positive reception. However, there are some mixed or negative opinions as well, with a few reviewers finding the films lacking in plot or criticizing the over-the-top violence. Overall, the general consensus suggests that people tend to like John Wick, especially fans of action movies.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. The URLs to those reviews are:\\n\\n- /review/rw4854296/?ref_=tt_urv (Review titled \"A Masterpiece & Brilliant Sequel\" for John Wick 3)\\n- /review/rw4862630/?ref_=tt_urv (Review titled \"Less is more\" for John Wick 3)'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick film series, the story centers around John Wick, a retired hitman who is drawn back into a violent underworld of assassins. The series begins with Wick seeking revenge after thugs steal his car and kill his beloved dog, which his late wife had gifted him, unleashing a relentless pursuit of vengeance against those who wronged him. As the series progresses, Wick becomes embroiled in a complex criminal universe involving a global assassin community, a powerful crime organization called the High Table, and a series of deadly conflicts. Throughout the movies, Wick fights to reclaim his peace while facing escalating threats, relentless assassins, and the consequences of his violent past. The series is known for its stylized action sequences, well-choreographed fight scenes, and exploration of themes like revenge, honor, and consequence.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/ds/7_nv6cl94zgbsb1gllmxxnkw0000gn/T/ipykernel_58871/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided reviews, people\\'s opinions on John Wick vary. Some reviewers, like MrHeraclius, express strong positive feelings and highly recommend the series, suggesting that many people do like the movies. Conversely, there is at least one negative review, such as the one by solidabs, who found John Wick 4 to be \"horrible\" and criticized various aspects of the film. Overall, the reviews indicate mixed opinions, with some people liking the series and others not enjoying certain installments.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL for that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick movies, John Wick is a retired assassin who is drawn back into a violent world of killing and revenge. In the first film, he comes out of retirement after a gang steals his car and kills his dog, which were personal losses that ignite his desire for vengeance. He then unleashes a relentless and brutal attack on those responsible. The sequel, John Wick Chapter 2, continues his story as he is pulled back into the dangerous assassin world when an Italian crime boss calls in a favor, leading Wick through a series of intense shootouts and action sequences across various locations. Overall, the series portrays John Wick as a highly skilled and deadly hitman who operates in a gritty, violent universe driven by revenge and consequence.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews in the context provided, people generally seem to like John Wick. Several reviews rate the film highly, praising its action sequences, style, and entertainment value, with ratings like 9, 8, and 10 out of 10. Many reviewers describe the film as fun, stylish, and a must-see for action fans. However, there are some mixed or negative reviews as well, especially for later installments, with ratings of 1, 2, or 4, criticizing the over-the-top action and perceived lack of plot or realism. Overall, the majority of reviews express a positive reception toward John Wick.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. One such review can be found at the following URL: \\n\\n/ review / rw4854296 / ?ref_=tt_urv\\n\\nPlease note that the URL is relative; you may need to add the base website address to access it directly.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'John Wick is about a retired hitman, played by Keanu Reeves, who comes out of retirement to seek revenge after a violent home invasion that results in the death of his dog and the theft of his car. The story highlights his relentless quest for vengeance against those who wronged him, unleashing a series of brutal and highly choreographed action sequences. Throughout the series, Wick navigates a criminal underworld, dealing with various enemies, including gangsters, assassins, and criminal organizations, while highlighting themes of revenge, consequences, and survival.'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. Many reviews are highly positive, praising its action, style, and entertainment value. Ratings often range from 8 to 10 out of 10, indicating a favorable reception. However, there are some less favorable opinions as well, with a few reviews giving low ratings or expressing that the film has lost some of its magic. Overall, the majority of reviewers seem to have liked the franchise.'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick movies, the main story follows a retired assassin named John Wick, played by Keanu Reeves, who seeks revenge after a series of tragic events. The original film begins with John Wick living a peaceful life after leaving his violent career. However, his peaceful existence is shattered when a young Russian punk and his accomplices break into his house, beat him up, kill his dog—his last remaining connection to his late wife—and steal his car. Unaware of his identity as a legendary hitman, they trigger John Wick's return to violence. Enraged and driven by revenge, Wick unleashes his lethal skills against those who wronged him, drawing the attention of criminal underworld forces, mobsters, and relentless killers. The story revolves around his quest for justice, revenge, and the consequences of his actions as he battles to protect what remains of his peace.\""
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 🏗️ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/keatnuxsuo/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/keatnuxsuo/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 100 documents from data/\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import CSVLoader\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to your CSV files directory\n",
        "path = \"data/\"\n",
        "\n",
        "# Method 1: Using DirectoryLoader with CSVLoader as the loader_cls\n",
        "csv_loader = DirectoryLoader(\n",
        "    path,\n",
        "    glob=\"*.csv\",  # Only get CSV files\n",
        "    loader_cls=CSVLoader\n",
        ")\n",
        "\n",
        "# Load all CSV files\n",
        "try:\n",
        "    movie_docs = csv_loader.load()\n",
        "    print(f\"Loaded {len(documents)} documents from {path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error with DirectoryLoader: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate SDG for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30e60a3d35e44ddfa4101ba33fd2b72c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/84 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16c79c7a212e4918bd2cd3527a54dce5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 167161cf-f8e1-4b16-ab62-80e2967b8eac does not have a summary. Skipping filtering.\n",
            "Node beec6591-9182-4870-a7a5-c4b23b7220d3 does not have a summary. Skipping filtering.\n",
            "Node d10ca170-2e65-4812-8432-a342ec864872 does not have a summary. Skipping filtering.\n",
            "Node 3648ad64-eeba-43c2-b8ce-022c84e676ce does not have a summary. Skipping filtering.\n",
            "Node 4b9f2de0-e3d3-481d-8c3e-38807307bdb7 does not have a summary. Skipping filtering.\n",
            "Node 98cf99ea-e3a6-46fa-a088-b69fa38dcc1b does not have a summary. Skipping filtering.\n",
            "Node ddbfe3ed-b47e-4906-a5d7-9c5ffa469f45 does not have a summary. Skipping filtering.\n",
            "Node f94f9b3c-1adb-4e76-8e9b-05469972bd55 does not have a summary. Skipping filtering.\n",
            "Node b732795c-3533-46bf-8437-8f297d1d2ad6 does not have a summary. Skipping filtering.\n",
            "Node 846fb9e4-e984-4605-8214-a67b3ccaa9d4 does not have a summary. Skipping filtering.\n",
            "Node 399cb61f-66c5-436d-b98e-adf0f5a1d524 does not have a summary. Skipping filtering.\n",
            "Node dd5b85c9-91fb-4dd8-b196-bf2daa6fbf3c does not have a summary. Skipping filtering.\n",
            "Node 7bbe8467-fd94-4844-9fe7-4e52595f8117 does not have a summary. Skipping filtering.\n",
            "Node c266f5e9-b964-4c9e-99bf-d2ba48abb883 does not have a summary. Skipping filtering.\n",
            "Node 3956b922-7271-47a1-a087-2b82185a76ee does not have a summary. Skipping filtering.\n",
            "Node 56a44fa2-454b-40a2-bd25-40ac4e81a25a does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abc20404dfb548d0b28918ac8f7c3837",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/257 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "505570c2a0564ae389aa2569a68ba5aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55b7cc22585a4c9da1c0d2cab961fe2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "553b742e26e94af69b12fae61aeb601f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78698f903c6f42b6a1925ab42f9d1793",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(movie_docs, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Liam Neeson in John Wick?</td>\n",
              "      <td>[: 0\\nReview_Date: 6 May 2015\\nAuthor: lnvicta...</td>\n",
              "      <td>The review compares John Wick to Taken but wit...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who is CountJonnie?</td>\n",
              "      <td>[: 1\\nReview_Date: 17 January 2015\\nAuthor: Co...</td>\n",
              "      <td>CountJonnie is the author of the review dated ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why is John Wick like so popular and why peopl...</td>\n",
              "      <td>[: 2\\nReview_Date: 5 May 2023\\nAuthor: Coventr...</td>\n",
              "      <td>The review mentions that after the success of ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What makes John Wick stand out among action mo...</td>\n",
              "      <td>[: 3\\nReview_Date: 28 September 2018\\nAuthor: ...</td>\n",
              "      <td>John Wick has a very simple revenge story, but...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do the critiqe of action scenes and backgr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 3\\nReview_Date: 27 May 2019\\nAut...</td>\n",
              "      <td>The critique of action sequences, noting that ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How does the fight choreography in John Wick c...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 3\\nReview_Date: 28 September 201...</td>\n",
              "      <td>The fight choreography in John Wick significan...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the revent thriller nerrative in John...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 21\\nReview_Date: 8 February 2017...</td>\n",
              "      <td>The review describes John Wick as a bloodier, ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How do critics criticize the artistic quality ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 9\\nReview_Date: 30 March 2023\\nA...</td>\n",
              "      <td>The reviews indicate that the John Wick movies...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>John Wick 3 Parabellum and John Wick 4 how the...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 20\\nReview_Date: 23 March 2023\\n...</td>\n",
              "      <td>According to the reviews, John Wick: Chapter 3...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Chapter 3 better than Chapter 2 or not?</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 4\\nReview_Date: 13 February 2017...</td>\n",
              "      <td>Based on the reviews, Chapter 2 is described a...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does the film depict the Russian Mafia's r...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 18\\nReview_Date: 10 September 20...</td>\n",
              "      <td>The film shows that after John Wick's wife die...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How do the Russian mobster and his gang in Joh...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 18\\nReview_Date: 10 September 20...</td>\n",
              "      <td>In the John Wick movies, the Russian mobster a...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0                           Liam Neeson in John Wick?   \n",
              "1                                 Who is CountJonnie?   \n",
              "2   Why is John Wick like so popular and why peopl...   \n",
              "3   What makes John Wick stand out among action mo...   \n",
              "4   How do the critiqe of action scenes and backgr...   \n",
              "5   How does the fight choreography in John Wick c...   \n",
              "6   How does the revent thriller nerrative in John...   \n",
              "7   How do critics criticize the artistic quality ...   \n",
              "8   John Wick 3 Parabellum and John Wick 4 how the...   \n",
              "9             Chapter 3 better than Chapter 2 or not?   \n",
              "10  How does the film depict the Russian Mafia's r...   \n",
              "11  How do the Russian mobster and his gang in Joh...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [: 0\\nReview_Date: 6 May 2015\\nAuthor: lnvicta...   \n",
              "1   [: 1\\nReview_Date: 17 January 2015\\nAuthor: Co...   \n",
              "2   [: 2\\nReview_Date: 5 May 2023\\nAuthor: Coventr...   \n",
              "3   [: 3\\nReview_Date: 28 September 2018\\nAuthor: ...   \n",
              "4   [<1-hop>\\n\\n: 3\\nReview_Date: 27 May 2019\\nAut...   \n",
              "5   [<1-hop>\\n\\n: 3\\nReview_Date: 28 September 201...   \n",
              "6   [<1-hop>\\n\\n: 21\\nReview_Date: 8 February 2017...   \n",
              "7   [<1-hop>\\n\\n: 9\\nReview_Date: 30 March 2023\\nA...   \n",
              "8   [<1-hop>\\n\\n: 20\\nReview_Date: 23 March 2023\\n...   \n",
              "9   [<1-hop>\\n\\n: 4\\nReview_Date: 13 February 2017...   \n",
              "10  [<1-hop>\\n\\n: 18\\nReview_Date: 10 September 20...   \n",
              "11  [<1-hop>\\n\\n: 18\\nReview_Date: 10 September 20...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   The review compares John Wick to Taken but wit...   \n",
              "1   CountJonnie is the author of the review dated ...   \n",
              "2   The review mentions that after the success of ...   \n",
              "3   John Wick has a very simple revenge story, but...   \n",
              "4   The critique of action sequences, noting that ...   \n",
              "5   The fight choreography in John Wick significan...   \n",
              "6   The review describes John Wick as a bloodier, ...   \n",
              "7   The reviews indicate that the John Wick movies...   \n",
              "8   According to the reviews, John Wick: Chapter 3...   \n",
              "9   Based on the reviews, Chapter 2 is described a...   \n",
              "10  The film shows that after John Wick's wife die...   \n",
              "11  In the John Wick movies, the Russian mobster a...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Evaluation Dataset (Question/Answer pairs) for each retreiver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from ragas import EvaluationDataset\n",
        "\n",
        "def create_eval_dataset(retriever_chain, dataset, name=\"retrieval\"):\n",
        "    \"\"\"\n",
        "    create a Ragas EvaluationDataset\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    retriever_chain : The retrieval chain to evaluate\n",
        "    dataset : The dataset containing test samples\n",
        "    name : Name of the retriever (for logging purposes)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    EvaluationDataset: A Ragas evaluation dataset containing the results\n",
        "    \"\"\"\n",
        "    retrieval_data = []\n",
        "    \n",
        "    # Run the evaluation for this retriever\n",
        "    for test_row in dataset:\n",
        "        response = retriever_chain.invoke({\"question\": test_row.eval_sample.user_input})\n",
        "        \n",
        "        # Store results in the correct format for Ragas\n",
        "        retrieval_data.append({\n",
        "            \"user_input\": test_row.eval_sample.user_input,\n",
        "            \"retrieved_contexts\": [context.page_content for context in response[\"context\"]],\n",
        "            \"reference_contexts\": test_row.eval_sample.reference_contexts,\n",
        "            \"response\": response[\"response\"].content,\n",
        "            \"reference\": test_row.eval_sample.reference\n",
        "        })\n",
        "    \n",
        "    # Create the Ragas EvaluationDataset\n",
        "    eval_dataset = EvaluationDataset.from_list(retrieval_data)\n",
        "    \n",
        "    print(f\"Created {name} dataset with {len(retrieval_data)} entries\")\n",
        "    return eval_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created naive_retrieval dataset with 12 entries\n"
          ]
        }
      ],
      "source": [
        "eval_naive_retrieval_data = create_eval_dataset(naive_retrieval_chain, dataset, \"naive_retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created naive_retrieval dataset with 12 entries\n",
            "Created bm25_retrieval dataset with 12 entries\n",
            "Created multi_query_retrieval dataset with 12 entries\n",
            "Created parent_document_retrieval dataset with 12 entries\n",
            "Created ensemble_retrieval dataset with 12 entries\n"
          ]
        }
      ],
      "source": [
        "eval_naive_retrieval_data = create_eval_dataset(naive_retrieval_chain, dataset, \"naive_retrieval\")\n",
        "eval_bm25_retrieval_data = create_eval_dataset(bm25_retrieval_chain, dataset, \"bm25_retrieval\")\n",
        "eval_multi_retrieval_data = create_eval_dataset(multi_query_retrieval_chain, dataset, \"multi_query_retrieval\")\n",
        "eval_parent_retrieval_data = create_eval_dataset(parent_document_retrieval_chain, dataset, \"parent_document_retrieval\")\n",
        "eval_ensemble_retrieval_data = create_eval_dataset(ensemble_retrieval_chain, dataset, \"ensemble_retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created compression_retrieval dataset with 12 entries\n"
          ]
        }
      ],
      "source": [
        "#run seperately cause of API limit\n",
        "eval_compression_retrieval_data = create_eval_dataset(contextual_compression_retrieval_chain, dataset, \"compression_retrieval\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run RAGAS Evaluation Metrics for all retreivers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "\n",
        "def evaluate_retriever_performance(eval_dataset, evaluator_llm, name=\"retrieval\", timeout=360):\n",
        "    \"\"\"\n",
        "    Evaluate a retriever's performance using Ragas metrics\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    eval_dataset : The Ragas EvaluationDataset containing retrieval results\n",
        "    evaluator_llm : The LLM to use for evaluation\n",
        "    name : Name of the retriever (for reporting purposes)\n",
        "    timeout : Timeout in seconds for the evaluation\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict: The evaluation results\n",
        "    \"\"\"\n",
        "    # Set up custom run configuration\n",
        "    custom_run_config = RunConfig(timeout=timeout)\n",
        "    \n",
        "    # Run the evaluation\n",
        "    print(f\"Evaluating {name} performance...\")\n",
        "    results = evaluate(\n",
        "        dataset=eval_dataset,\n",
        "        metrics=[\n",
        "            LLMContextRecall(), \n",
        "            Faithfulness(), \n",
        "            FactualCorrectness(), \n",
        "            ResponseRelevancy(), \n",
        "            ContextEntityRecall(), \n",
        "            NoiseSensitivity()\n",
        "        ],\n",
        "        llm=evaluator_llm,\n",
        "        run_config=custom_run_config\n",
        "    )\n",
        "    \n",
        "    print(f\"Evaluation of {name} complete!\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating naive_retrieval performance...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27044642bca44ceaaf2e23dbeecd80f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[17]: TimeoutError()\n",
            "Exception raised in Job[23]: TimeoutError()\n",
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[47]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[65]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation of naive_retrieval complete!\n"
          ]
        }
      ],
      "source": [
        "naive_results = evaluate_retriever_performance(eval_naive_retrieval_data, evaluator_llm, \"naive_retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.6319, 'faithfulness': 0.8979, 'factual_correctness(mode=f1)': 0.3500, 'answer_relevancy': 0.8556, 'context_entity_recall': 0.5266, 'noise_sensitivity(mode=relevant)': 0.4306}"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating bm25_retrieval performance...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d094048db844b3faf1fd67f86325058",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[47]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation of bm25_retrieval complete!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.6458, 'faithfulness': 0.8410, 'factual_correctness(mode=f1)': 0.4025, 'answer_relevancy': 0.7922, 'context_entity_recall': 0.5188, 'noise_sensitivity(mode=relevant)': 0.2823}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_results = evaluate_retriever_performance(eval_bm25_retrieval_data, evaluator_llm, \"bm25_retrieval\")\n",
        "bm25_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating compression_retrieval performance...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14a8e23ff66c469fb62473c9fd724f07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation of compression_retrieval complete!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.5903, 'faithfulness': 0.8661, 'factual_correctness(mode=f1)': 0.4233, 'answer_relevancy': 0.7900, 'context_entity_recall': 0.5097, 'noise_sensitivity(mode=relevant)': 0.3218}"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compression_results = evaluate_retriever_performance(eval_compression_retrieval_data, evaluator_llm, \"compression_retrieval\")\n",
        "compression_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating multi_query_retrieval performance...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d572eff075f948458cfc3b7867f79357",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[17]: TimeoutError()\n",
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[47]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[65]: TimeoutError()\n",
            "Exception raised in Job[71]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation of multi_query_retrieval complete!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.7014, 'faithfulness': 0.9674, 'factual_correctness(mode=f1)': 0.3600, 'answer_relevancy': 0.8702, 'context_entity_recall': 0.4472, 'noise_sensitivity(mode=relevant)': 0.5091}"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_results = evaluate_retriever_performance(eval_multi_retrieval_data, evaluator_llm, \"multi_query_retrieval\")\n",
        "multi_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating parent_document_retrieval performance...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ab0a5b2d9e44682b537b3f27bfcfc1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation of parent_document_retrieval complete!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.5486, 'faithfulness': 0.6469, 'factual_correctness(mode=f1)': 0.4608, 'answer_relevancy': 0.7883, 'context_entity_recall': 0.5990, 'noise_sensitivity(mode=relevant)': 0.1934}"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_results = evaluate_retriever_performance(eval_parent_retrieval_data, evaluator_llm, \"parent_document_retrieval\")\n",
        "parent_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating ensemble_retrieval performance...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a4501fa95be45d98d6d6b54d05a370e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[17]: TimeoutError()\n",
            "Exception raised in Job[23]: TimeoutError()\n",
            "Exception raised in Job[29]: TimeoutError()\n",
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[47]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[59]: TimeoutError()\n",
            "Exception raised in Job[65]: TimeoutError()\n",
            "Exception raised in Job[71]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation of ensemble_retrieval complete!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.8333, 'faithfulness': 0.9552, 'factual_correctness(mode=f1)': 0.4175, 'answer_relevancy': 0.8654, 'context_entity_recall': 0.4681, 'noise_sensitivity(mode=relevant)': 0.1667}"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_results = evaluate_retriever_performance(eval_ensemble_retrieval_data, evaluator_llm, \"ensemble_retrieval\")\n",
        "ensemble_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combining all the metric results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# List of all result variables\n",
        "all_results = [naive_results, bm25_results, compression_results, multi_results, parent_results, ensemble_results]\n",
        "retriever_names = ['Naive', 'BM25', 'Contextual Compression', 'Multi-Query', 'Parent Document', 'Ensemble']\n",
        "\n",
        "# Get all unique metrics from the first item in each result's scores list\n",
        "all_metrics = set()\n",
        "for result in all_results:\n",
        "    if hasattr(result, 'scores') and isinstance(result.scores, list) and len(result.scores) > 0:\n",
        "        for score_dict in result.scores:\n",
        "            if isinstance(score_dict, dict):\n",
        "                all_metrics.update(score_dict.keys())\n",
        "\n",
        "# Create DataFrame with results\n",
        "data = {'Retriever': retriever_names}\n",
        "\n",
        "# Function to safely compute mean of a metric across all score dictionaries\n",
        "def compute_metric_mean(result_obj, metric_name):\n",
        "    if not hasattr(result_obj, 'scores') or not isinstance(result_obj.scores, list):\n",
        "        return None\n",
        "    \n",
        "    values = []\n",
        "    for score_dict in result_obj.scores:\n",
        "        if isinstance(score_dict, dict) and metric_name in score_dict:\n",
        "            value = score_dict[metric_name]\n",
        "            if value is not None and not (isinstance(value, float) and np.isnan(value)):\n",
        "                values.append(float(value))\n",
        "    \n",
        "    if values:\n",
        "        return np.mean(values)\n",
        "    return None\n",
        "\n",
        "# Add each metric to the DataFrame\n",
        "for metric in sorted(all_metrics):\n",
        "    data[metric.capitalize().replace('_', ' ')] = [\n",
        "        compute_metric_mean(result, metric) for result in all_results\n",
        "    ]\n",
        "# Create the comparison DataFrame\n",
        "comparison_df = pd.DataFrame(data)\n",
        "\n",
        "# Format numeric values as percentages with 2 decimal places\n",
        "for col in comparison_df.columns:\n",
        "    if col != 'Retriever' and col != 'Total Cost ($)':\n",
        "        comparison_df[col] = comparison_df[col].apply(\n",
        "            lambda x: f\"{x*100:.2f}%\" if isinstance(x, (int, float)) else x\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get Costs, Latency and Tokens from Langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langsmith import Client\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize LangSmith client\n",
        "client = Client(api_key=os.environ.get(\"LANGSMITH_API_KEY\"))\n",
        "\n",
        "# List of retrievers and their run IDs\n",
        "retriever_names = ['Naive', 'BM25', 'Contextual Compression', 'Multi-Query', 'Parent Document', 'Ensemble']\n",
        "run_ids = [\n",
        "    \"13573b02-7cfa-4879-baab-aebb209863be\",  # Naive\n",
        "    \"ff241b88-ffec-4432-9ea5-efd1d451d549\",  # BM25\n",
        "    \"94f14b15-e31f-4044-abd2-269445773050\",  # Contextual Compression\n",
        "    \"cd407e77-43c1-42f1-b43b-3dd37436a61c\",  # Multi-Query\n",
        "    \"f8c90244-388e-41d2-a409-f2d79ea1a8e7\",  # Parent Document\n",
        "    \"c83157b1-b035-4f57-bd6b-fc097d88074d\"   # Ensemble\n",
        "]\n",
        "\n",
        "# Function to get metrics from LangSmith run\n",
        "def get_run_metrics(run_id):\n",
        "    try:\n",
        "        # Get run details from LangSmith\n",
        "        run = client.read_run(run_id)\n",
        "        \n",
        "        # Try to get cost from various attributes\n",
        "        cost = None\n",
        "        if hasattr(run, 'total_cost'):\n",
        "            cost = run.total_cost\n",
        "        elif hasattr(run, 'prompt_cost') and hasattr(run, 'completion_cost'):\n",
        "            prompt_cost = run.prompt_cost or 0\n",
        "            completion_cost = run.completion_cost or 0\n",
        "            cost = prompt_cost + completion_cost\n",
        "        \n",
        "        # Get token counts if available\n",
        "        tokens = None\n",
        "        if hasattr(run, 'total_tokens'):\n",
        "            tokens = run.total_tokens\n",
        "        \n",
        "        # Calculate latency from timestamps\n",
        "        latency = None\n",
        "        if hasattr(run, 'start_time') and hasattr(run, 'end_time'):\n",
        "            start_time = run.start_time\n",
        "            end_time = run.end_time\n",
        "            if start_time and end_time:\n",
        "                latency = (end_time - start_time).total_seconds()\n",
        "        \n",
        "        return cost, latency, tokens\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting metrics for run {run_id}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Get metrics for each retriever\n",
        "metrics = []\n",
        "for i, run_id in enumerate(run_ids):\n",
        "    cost, latency, tokens = get_run_metrics(run_id)\n",
        "    metrics.append({\n",
        "        'Retriever': retriever_names[i],\n",
        "        'Cost ($)': cost,\n",
        "        'Latency (s)': latency,\n",
        "        'Tokens': tokens\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine all metrics, cost, latency and tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Retriever</th>\n",
              "      <th>Answer relevancy</th>\n",
              "      <th>Context entity recall</th>\n",
              "      <th>Context recall</th>\n",
              "      <th>Factual correctness(mode=f1)</th>\n",
              "      <th>Faithfulness</th>\n",
              "      <th>Noise sensitivity(mode=relevant)</th>\n",
              "      <th>Cost ($)</th>\n",
              "      <th>Latency (s)</th>\n",
              "      <th>Tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive</td>\n",
              "      <td>85.56%</td>\n",
              "      <td>52.66%</td>\n",
              "      <td>63.19%</td>\n",
              "      <td>35.00%</td>\n",
              "      <td>89.79%</td>\n",
              "      <td>43.06%</td>\n",
              "      <td>0.5175488</td>\n",
              "      <td>454.344248</td>\n",
              "      <td>658064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BM25</td>\n",
              "      <td>79.22%</td>\n",
              "      <td>51.88%</td>\n",
              "      <td>64.58%</td>\n",
              "      <td>40.25%</td>\n",
              "      <td>84.10%</td>\n",
              "      <td>28.23%</td>\n",
              "      <td>0.3220576</td>\n",
              "      <td>405.710811</td>\n",
              "      <td>402238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Contextual Compression</td>\n",
              "      <td>79.00%</td>\n",
              "      <td>50.97%</td>\n",
              "      <td>59.03%</td>\n",
              "      <td>42.33%</td>\n",
              "      <td>86.61%</td>\n",
              "      <td>32.18%</td>\n",
              "      <td>0.288856</td>\n",
              "      <td>304.538759</td>\n",
              "      <td>359449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Multi-Query</td>\n",
              "      <td>87.02%</td>\n",
              "      <td>44.72%</td>\n",
              "      <td>70.14%</td>\n",
              "      <td>36.00%</td>\n",
              "      <td>96.74%</td>\n",
              "      <td>50.91%</td>\n",
              "      <td>0.564982</td>\n",
              "      <td>509.805455</td>\n",
              "      <td>743233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Parent Document</td>\n",
              "      <td>78.83%</td>\n",
              "      <td>59.90%</td>\n",
              "      <td>54.86%</td>\n",
              "      <td>46.08%</td>\n",
              "      <td>64.69%</td>\n",
              "      <td>19.34%</td>\n",
              "      <td>0.2515708</td>\n",
              "      <td>293.522741</td>\n",
              "      <td>310327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>86.54%</td>\n",
              "      <td>46.81%</td>\n",
              "      <td>83.33%</td>\n",
              "      <td>41.75%</td>\n",
              "      <td>95.52%</td>\n",
              "      <td>16.67%</td>\n",
              "      <td>0.5670152</td>\n",
              "      <td>483.225317</td>\n",
              "      <td>753854</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Retriever Answer relevancy Context entity recall  \\\n",
              "0                   Naive           85.56%                52.66%   \n",
              "1                    BM25           79.22%                51.88%   \n",
              "2  Contextual Compression           79.00%                50.97%   \n",
              "3             Multi-Query           87.02%                44.72%   \n",
              "4         Parent Document           78.83%                59.90%   \n",
              "5                Ensemble           86.54%                46.81%   \n",
              "\n",
              "  Context recall Factual correctness(mode=f1) Faithfulness  \\\n",
              "0         63.19%                       35.00%       89.79%   \n",
              "1         64.58%                       40.25%       84.10%   \n",
              "2         59.03%                       42.33%       86.61%   \n",
              "3         70.14%                       36.00%       96.74%   \n",
              "4         54.86%                       46.08%       64.69%   \n",
              "5         83.33%                       41.75%       95.52%   \n",
              "\n",
              "  Noise sensitivity(mode=relevant)   Cost ($)  Latency (s)  Tokens  \n",
              "0                           43.06%  0.5175488   454.344248  658064  \n",
              "1                           28.23%  0.3220576   405.710811  402238  \n",
              "2                           32.18%   0.288856   304.538759  359449  \n",
              "3                           50.91%   0.564982   509.805455  743233  \n",
              "4                           19.34%  0.2515708   293.522741  310327  \n",
              "5                           16.67%  0.5670152   483.225317  753854  "
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_metrics = pd.merge(comparison_df, metrics_df, on='Retriever')\n",
        "all_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis\n",
        "\n",
        "**Answer relevancy**\n",
        "- Highest: Multi-Query (87.02%), Ensemble (86.54%), Naive (85.56%)\n",
        "- Lowest: Parent Document (78.83%), Contextual Compression (79.00%), BM25 (79.22%)\n",
        "- Analysis: \n",
        "  - **Multi-Query** and **Ensemble** can synthesize information from multiple sources/queries, raising the odds of finding directly relevant snippets\n",
        "  - **Naive** is surprisingly high—possibly due to direct matching on clear queries in your dataset (e.g., “Who is Count Jonnie?”).\n",
        "  - **Parent Document** focuses on whole docs, not just direct matches, which can dilute relevancy.\n",
        "\n",
        "**Context Entity Recall / Context Recall**\n",
        "- Highest (Entity Recall): Parent Document (59.90%)\n",
        "- Lowest (Entity Recall): Multi-Query (44.72%)\n",
        "- Highest (Context Recall): Ensemble (83.33%), Multi-Query (70.14%)\n",
        "- Lowest (Context Recall): Parent Document (54.86%), Contextual Compression (59.03%)\n",
        "- Analysis:\n",
        "  - **Parent Document** grabs more context entities, as it retrieves full docs (risk: more noise).\n",
        "  - **Ensemble** and **Multi-Query** excel in context recall by aggregating from different strategies, likely capturing more “edges” of the reference contexts.\n",
        "  - Some strategies **(BM25, Contextual Compression)** retrieve precise snippets, missing broader context.\n",
        "\n",
        "\n",
        "**Factual Correctness (F1)**\n",
        "- Highest: Parent Document (46.08%), Contextual Compression (42.33%), Ensemble (41.75%)\n",
        "- Lowest: Naive (35.00%), Multi-Query (36.00%)\n",
        "- Analysis:\n",
        "  - **Parent Document’s **recall of full docs helps surface more facts, but can risk noise/confusion.\n",
        "  - **Naive** and **Multi-Query** may overfit to “apparent” answers without complete factual support.\n",
        "\n",
        "**Faithfulness**\n",
        "- Highest: Multi-Query (96.74%), Ensemble (95.52%), Naive (89.79%)\n",
        "- Lowest: Parent Document (64.69%)\n",
        "- Analysis:\n",
        "  - **Multi-Query** and Ensemble provide answers closely supported by retrieved text.\n",
        "  - **Parent Document**’s low faithfulness is a classic risk: retrieving too much unrelated content.\n",
        "\n",
        "**Noise Sensitivity**\n",
        "- Lowest (Best): Ensemble (16.67%), Parent Document (19.34%)\n",
        "- Highest (Worst): Multi-Query (50.91%), Naive (43.06%)\n",
        "- Analysis:\n",
        "  - **Ensemble** and **Parent Document** approaches are robust to irrelevant info—either via ensembling or by diluting noise in larger context.\n",
        "  - **Multi-Query** and **Naive** may over-retrieve or pick up spurious matches (especially with long or complex questions).\n",
        "\n",
        "\n",
        "**Cost / Latency / Tokens**\n",
        "- Lowest Cost & Latency: Parent Document, Contextual Compression\n",
        "- Highest Cost & Latency: Ensemble, Multi-Query, Naive (due to large context or multiple queries)\n",
        "- Analysis:\n",
        "  - **Parent Document** and **Contextual Compression** are resource-efficient because \n",
        "    - Parent Document retriever fetches an entire document (or a large chunk), rather than splitting the query into many sub-queries or retrieving lots of small passages.\n",
        "    - Contextual Compression uses dense retrieval (embeddings) to directly return only the most relevant compressed snippets from the corpus, instead of large documents or multiple sub-queries.\n",
        "  - **Multi-Query** and **Ensemble** are more expensive—multiple calls, context merging, or model ensemble.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why Do Retrievers Perform Differently?\n",
        "\n",
        "**Retriever Strategies**\n",
        "- **Naive**: retrieves by simple keyword or passage match. Good for clear-cut Q&A, but falls down on complex/nuanced tasks (low F1).\n",
        "\n",
        "- **BM25**: Classic lexical match; performs reliably on explicit questions but struggles with paraphrasing and implied context (explains middling scores across most metrics).\n",
        "\n",
        "- **Contextual Compression:** Uses embeddings to “compress” relevant context; can miss details (lower recall) but is efficient, which suits focused fact retrieval.\n",
        "\n",
        "- **Multi-Query:** Splits queries, gathers context from multiple angles—great for high coverage and recall (especially for compound/multi-part questions), but at the cost of noise and higher resource use.\n",
        "\n",
        "- **Parent Document:** Retrieves entire docs—max context entity recall, but faithfulness suffers because not all context is always relevant (can confuse LLMs, but boosts F1 by “accidentally” surfacing more facts).\n",
        "\n",
        "- **Ensemble**: Combines several approaches, benefiting from their strengths (e.g., higher context recall, high faithfulness, low noise), but at the cost of higher latency and compute.\n",
        "\n",
        "---- \n",
        "**Testset Impact**\n",
        "- Short, Direct Queries (e.g., “Who is CountJonnie?”): **Naive** and **BM25** work fine; complex methods don’t add much value.\n",
        "\n",
        "- Multi-Hop/Compound Questions (e.g., “Why is John Wick so popular and how has it evolved?”): **Multi-Query**, **Ensemble**, and** Contextual Compression** outperform naive approaches by piecing together answers from multiple places.\n",
        "\n",
        "- Contextual Nuance (e.g., “How does critique of action scenes affect tone/quality?”): Methods with better context recall **(Ensemble, Multi-Query, Parent Document)** capture subtler points—snippets or full reviews with relevant critique.\n",
        "\n",
        "- Risk of Noise: **Parent Document** can pull in a lot of irrelevant info if the reference doc is long; **Ensemble** mitigates this by blending signals; **Multi-Query** risks high noise if sub-queries aren’t well-formed.\n",
        "\n",
        "---\n",
        "**Cost & Latency**\n",
        "- **Parent Document, Contextual Compression**: Fastest, cheapest—good for scaling, but may lack subtlety.\n",
        "\n",
        "- **Multi-Query, Ensemble**: Best for nuanced, compound reasoning but expensive and slow—justified for complex research tasks, not for real-time or cost-sensitive use cases.\n",
        "\n",
        "---\n",
        "**Conclusion**\n",
        "- If we want high answer relevancy and faithfulness for complex, multi-faceted movie Q&A, use **Ensemble or Multi-Query** but be aware of cost/latency.\n",
        "\n",
        "- For simple direct questions, **Naive/BM25** are surprisingly competitive and resource-efficient.\n",
        "\n",
        "- If cost/latency matters and you can tolerate lower recall/coverage, **Contextual Compression or Parent Document** suffice.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
